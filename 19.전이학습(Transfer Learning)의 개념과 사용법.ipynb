{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXxUA5P0inlj0BO36j6V03"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"nHFBTBzvnOzh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730179639651,"user_tz":-540,"elapsed":4363,"user":{"displayName":"서철규","userId":"08589483314836926095"}},"outputId":"5579fd61-c550-4f0e-aefb-58085b73313e"},"outputs":[{"output_type":"stream","name":"stdout","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torchvision import models # 다양한 학습 model을 포함하고 있는 module\n","\n","# model download\n","# vgg16 - 사전 학습 모델\n","# https://pytorch.org/vision/stable/models/generated/torchvision.models.vgg16.html#vgg16\n","# VGG16_Weights.DEFAULT - 사전학습된 가중치, VGG16_Weights.IMAGENET1K_V1 과 동일\n","pretrained_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n","print(pretrained_model)\n","\n","# 특성 추출기(features) 부분: Convolution layer(Conv2d)와 Pooling layer(MaxPool2d)로 구성\n","# Flatten(avgpool) 부분 - 2차원 이상의 tensor를 1차원 vector로 변환\n","# 분류기(classifier) - 1,000개의 label로 data를 분류 - 분류하려는 data에 맞게 수정 필요"]},{"cell_type":"code","source":["class TransferLearningModel(nn.Module):\n","\n","  def __init__(self, pretrained_model, feature_extractor):\n","    super().__init__()\n","\n","    if (feature_extractor):\n","      for param in pretrained_model.parameters():\n","        param.require_grad = False\n","\n","    # 학습 data에 맞게 새로운 classifier를 만든 후에,\n","    # 사전 학습 모델(Pre-Trained Model)의 classifier 부분을\n","    # 새로 만든 classifier로 변경\n","    pretrained_model.classifier = nn.Sequential(\n","        nn.Linear(pretrained_model.classifier[0].in_features, 128),\n","        nn.Linear(128, 2)\n","    )\n","\n","    self.model = pretrained_model\n","\n","  def forward(self, data):\n","    logits = self.model(data)\n","    return logits\n","\n","feature_extractor = True # True: Feature Extractor,  False: Fine Tuning\n","model = TransferLearningModel(pretrained_model, feature_extractor)\n","\n","criterion = nn.CrossEntropyLoss()\n","# 전이 학습(Transder Learning)의 Fine Tuning에서는\n","# 사전 학습 모델에서 사용된 가중치를 학습 data에 맞게 미세하게 조정해야 하므로\n","# 학습률(learning rate)을 lr=1e-6 으로 아주 적게 설정\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaKatBlTvTgW","executionInfo":{"status":"ok","timestamp":1730180249276,"user_tz":-540,"elapsed":305,"user":{"displayName":"서철규","userId":"08589483314836926095"}},"outputId":"990f6542-969e-495f-c05e-a0e8fe8337ff"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["TransferLearningModel(\n","  (model): VGG(\n","    (features): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (6): ReLU(inplace=True)\n","      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (8): ReLU(inplace=True)\n","      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (11): ReLU(inplace=True)\n","      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (13): ReLU(inplace=True)\n","      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (15): ReLU(inplace=True)\n","      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (18): ReLU(inplace=True)\n","      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (20): ReLU(inplace=True)\n","      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (22): ReLU(inplace=True)\n","      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (25): ReLU(inplace=True)\n","      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (27): ReLU(inplace=True)\n","      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (29): ReLU(inplace=True)\n","      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","    (classifier): Sequential(\n","      (0): Linear(in_features=25088, out_features=128, bias=True)\n","      (1): Linear(in_features=128, out_features=2, bias=True)\n","    )\n","  )\n",")\n"]}]}]}